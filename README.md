# 5329MLP
This project implements a modular MLP (Multi-Layer Perceptron) neural network training platform based on Python and Numpy, supporting the entire process from data loading, model building, batch training, automatic evaluation, model selection, to ablation experiments. The core functions of this project are divided into the following parts:

Data import and processing Supports data files in .npyformat as input; supports loading of training and test sets; automatically handles basic preprocessing operations such as data normalisation and label conversion; uses a custom DataLoader class to encapsulate data batch processing logic, and supports the setting of parameters such as batch_size and shuffle.
Model structure construction The model is implemented based on a custom Module base class and Sequential container; supports user-defined MLP network layers, the dimension of each layer (hidden_dims), the type of activation function, whether to use BatchNorm, whether to use Dropout, etc.; supports the following network components: fully connected layer (Linear) activation function: ReLU, GELU (implemented using an approximation function) Dropout layer Batch Normalization layer
Model training module automatically traverses all combinations of hyperparameters for batch training; supports SGD and Adam optimizers, and also supports parameter adjustment such as momentum, weight decay, beta1, beta2, eps, etc.; each model is automatically saved in .npzformat after training is complete; supports unified configuration of training parameters such as epochs, learning rate, batch size, optimizer, etc.
Model testing and evaluation automatically reads the saved model file and uniformly restores and reconstructs the model; The evaluation function in evaluation.pyis used to calculate the following metrics: Accuracy macro-F1 The evaluation results of all models are saved as a all_model_results.csvfile, which contains the model file name, accuracy, F1 score, hyperparameter information, etc.
Model selection and result output Automatically select the model with the highest macro-F1 score among all models as the ‘best model’; The accuracy, F1 score and corresponding hyperparameter configuration of the best model are output; the visualization is saved as an image best_model_result.png.
Ablation experiment Based on the structure of the ‘best model’, the following three structural ablation experiments are performed: Remove Dropout (set to 0) Turn off BatchNorm Replace the activation function from ReLU to GELU Each structural variant is reinitialised and trained to ensure the fairness of the experiment; After all variants are tested, the ablation comparison chart ablation_result.pngis automatically generated to show the changes in Accuracy and Macro-F1; The specific hyperparameter configuration of each ablation experiment is also output for easy tracking and reproduction.